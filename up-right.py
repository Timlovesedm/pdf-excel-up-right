import streamlit as st
import pandas as pd
import pdfplumber
import io
import re
from collections import defaultdict

# --- ãƒ„ãƒ¼ãƒ«â‘ ï¼šPDFã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°ï¼ˆå¤‰æ›´ãªã—ï¼‰ ---
def extract_tables_from_multiple_pdfs(pdf_files, keywords, start_page, end_page):
    all_rows = []
    if not keywords:
        st.error("â— ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", icon="ğŸš¨")
        return None
    for pdf_file in pdf_files:
        all_rows.append([f"ãƒ•ã‚¡ã‚¤ãƒ«å: {pdf_file.name}"])
        all_rows.append([])
        found_in_file = False
        try:
            with pdfplumber.open(pdf_file) as pdf:
                start_index = start_page - 1 if start_page else 0
                end_index = end_page if end_page else len(pdf.pages)
                target_pages = pdf.pages[start_index:end_index]
                for page in target_pages:
                    text = page.extract_text() or ""
                    if any(kw in text for kw in keywords):
                        found_in_file = True
                        tables = page.extract_tables()
                        for table_index, table in enumerate(tables):
                            if not table:
                                continue
                            all_rows.append([f"--- ãƒšãƒ¼ã‚¸ {page.page_number} / ãƒ†ãƒ¼ãƒ–ãƒ« {table_index + 1} ---"])
                            for row in table:
                                cleaned_row = ["" if item is None else str(item).replace("\n", " ") for item in row]
                                all_rows.append(cleaned_row)
                            all_rows.append([])
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{pdf_file.name}ã€å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", icon="ğŸ”¥")
            continue
        if not found_in_file:
            st.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{pdf_file.name}ã€ã§ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€è¡¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", icon="âš ï¸")

    if not any(r for r in all_rows if r):
        return None
    return pd.DataFrame(all_rows)

# --- æ¨ªæ–¹å‘çµ±åˆ ---
def horizontal_merge(df_chunk):
    df_chunk = df_chunk.fillna("")
    merged_df = pd.DataFrame()
    # åˆ—ãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã§çµ±åˆ
    n_cols = df_chunk.shape[1]
    col_indices = list(range(0, n_cols, 3))  # 3åˆ—ãšã¤ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’æƒ³å®šï¼ˆå·¦ã€ä¸­å¤®ã€å³ï¼‰
    for idx, start_col in enumerate(col_indices):
        left_col = start_col
        right_col = min(start_col + 2, n_cols - 1)
        block_df = df_chunk.iloc[:, [left_col, right_col]].copy()
        block_df.columns = ["é …ç›®", f"å€¤_{idx+1}"]
        block_df["é …ç›®"] = block_df["é …ç›®"].astype(str).str.strip()
        block_df[f"å€¤_{idx+1}"] = pd.to_numeric(block_df[f"å€¤_{idx+1}"].astype(str).str.replace(",", ""), errors='coerce').fillna(0)
        if merged_df.empty:
            merged_df = block_df
        else:
            merged_df = pd.merge(merged_df, block_df, on="é …ç›®", how="outer")
    merged_df.fillna(0, inplace=True)
    # å„ãƒ–ãƒ­ãƒƒã‚¯ã®ä¸€ç•ªä¸Šã®æ•°å€¤ã§ã‚½ãƒ¼ãƒˆ
    first_value_cols = [col for col in merged_df.columns if col.startswith("å€¤_")]
    if first_value_cols:
        merged_df = merged_df.sort_values(by=first_value_cols[0], ascending=True).reset_index(drop=True)
    return merged_df

# --- ç¸¦æ–¹å‘çµ±åˆï¼ˆæ—¢å­˜ã®ç°¡ç•¥ç‰ˆï¼‰ ---
def vertical_merge(df_chunk):
    df_chunk = df_chunk.fillna("")
    df_chunk.columns = ["é …ç›®", "å€¤"]
    df_chunk["é …ç›®"] = df_chunk["é …ç›®"].astype(str).str.strip()
    df_chunk["å€¤"] = pd.to_numeric(df_chunk["å€¤"].astype(str).str.replace(",", ""), errors='coerce').fillna(0)
    return df_chunk

# --- ãƒ„ãƒ¼ãƒ«â‘¡ï¼šExcelçµ±åˆå‡¦ç† ---
def process_excel(file, direction="ç¸¦"):
    try:
        xls = pd.ExcelFile(file)
        sheet_name_to_read = "æŠ½å‡ºçµæœ" if "æŠ½å‡ºçµæœ" in xls.sheet_names else xls.sheet_names[0]
        df_full = pd.read_excel(xls, sheet_name=sheet_name_to_read, header=None)
    except Exception as e:
        st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return None

    if direction == "ç¸¦":
        result_df = vertical_merge(df_full)
    else:
        result_df = horizontal_merge(df_full)
    return result_df

# --- Streamlit UI ---
st.set_page_config(page_title="å¤šæ©Ÿèƒ½ãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("ğŸ“„ğŸ“Š å¤šæ©Ÿèƒ½ãƒ„ãƒ¼ãƒ«")

# --- ãƒ„ãƒ¼ãƒ«â‘  ---
with st.container():
    st.header("ãƒ„ãƒ¼ãƒ«â‘ ï¼šPDFè¡¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡º")
    pdf_files = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰", type="pdf", accept_multiple_files=True)
    keyword_input_str = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰")
    col1, col2 = st.columns(2)
    start_page_input = col1.text_input("é–‹å§‹ãƒšãƒ¼ã‚¸", placeholder="ä¾‹: 5")
    end_page_input = col2.text_input("çµ‚äº†ãƒšãƒ¼ã‚¸", placeholder="ä¾‹: 10")
    if st.button("æŠ½å‡ºé–‹å§‹ â–¶ï¸"):
        if pdf_files:
            keywords = [kw.strip() for kw in keyword_input_str.split(",") if kw.strip()]
            start_page = int(start_page_input) if start_page_input.isdigit() else None
            end_page = int(end_page_input) if end_page_input.isdigit() else None
            with st.spinner("PDFè§£æä¸­..."):
                df_result = extract_tables_from_multiple_pdfs(pdf_files, keywords, start_page, end_page)
                if df_result is not None and not df_result.empty:
                    st.success("æŠ½å‡ºå®Œäº†ï¼", icon="âœ…")
                    st.dataframe(df_result)
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                        df_result.to_excel(writer, index=False, header=False, sheet_name="æŠ½å‡ºçµæœ")
                    st.download_button(
                        label="ğŸ“¥ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=output.getvalue(),
                        file_name="æŠ½å‡ºçµæœ_ã¾ã¨ã‚.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )
        else:
            st.error("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚", icon="ğŸš¨")

st.divider()

# --- ãƒ„ãƒ¼ãƒ«â‘¡ ---
with st.container():
    st.header("ãƒ„ãƒ¼ãƒ«â‘¡ï¼šExcelçµ±åˆ")
    excel_file = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])
    merge_direction = st.radio("çµ±åˆæ–¹å‘ã‚’é¸æŠ", ["ç¸¦æ–¹å‘", "æ¨ªæ–¹å‘"])
    if st.button("çµ±åˆã¾ã¨ã‚è¡¨ã‚’ä½œæˆ â–¶ï¸", disabled=(excel_file is None)):
        with st.spinner("ãƒ‡ãƒ¼ã‚¿æ•´ç†ä¸­..."):
            merged_df = process_excel(excel_file, direction=merge_direction)
            if merged_df is not None:
                st.success("çµ±åˆå®Œäº†ï¼", icon="âœ…")
                st.dataframe(merged_df)
                output_excel = io.BytesIO()
                with pd.ExcelWriter(output_excel, engine="xlsxwriter") as writer:
                    merged_df.to_excel(writer, sheet_name="çµ±åˆã¾ã¨ã‚è¡¨", index=False)
                base_name_input = excel_file.name.rsplit('.xlsx', 1)[0]
                download_filename = f"{base_name_input}_çµ±åˆ.xlsx"
                st.download_button(
                    label="ğŸ“¥ çµ±åˆã¾ã¨ã‚è¡¨ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=output_excel.getvalue(),
                    file_name=download_filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )
